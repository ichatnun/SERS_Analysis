{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install webcolors\n",
    "# !{sys.executable} -m pip install plotly==5.7.0\n",
    "# !{sys.executable} -m pip install --upgrade nbformat\n",
    "# !{sys.executable} -m pip install tune-sklearn ray[tune]\n",
    "# !{sys.executable} -m pip install packaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Import necessary packages\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import pdb, itertools, os, time, sys, re, random, pickle, shutil\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from utils import *\n",
    "from config import current_config as config\n",
    "from models.performAnalysis import performAnalysis\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Sans\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Check the validity of the paremeters\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ML methods that will be used include ['pca', 'pc-lda', 'pc-rf', 'lda-rf', 'pc-svm', 'lda-svm']\n"
     ]
    }
   ],
   "source": [
    "supported_classif_methods = ['pc-lda', 'rf', 'pc-rf', 'lda-rf', 'svm','pc-svm','lda-svm']\n",
    "supported_ML_methods = supported_classif_methods + ['pca']\n",
    "\n",
    "\n",
    "ML_method_list = config.ML_method_list\n",
    "# Get rid of unsupported ML methods\n",
    "for curr_ML_method in ML_method_list:\n",
    "    if not (curr_ML_method in supported_ML_methods):\n",
    "        ML_method_list.remove(curr_ML_method)\n",
    "        print(curr_ML_method,'is currently unsupported')\n",
    "print('The ML methods that will be used include', ML_method_list)\n",
    "\n",
    "if not (config.data_split_method in ['intra','inter','by-folders']):\n",
    "    print('Invalid data_split_method.')\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Prepare some information\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such experiment. These are all existing experiments: \n",
      "/home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15\n",
      "Input [c] if you want to run these experiments\n",
      "--Return--\n",
      "> <ipython-input-4-96d0b79f7a56>(23)<module>()->None\n",
      "-> pdb.set_trace()\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  c\n"
     ]
    }
   ],
   "source": [
    "# Generate a list of random seeds to perform experiments\n",
    "if config.data_split_method == 'intra':\n",
    "    random_seed_list = np.random.randint(config.num_repetitions_intra*10, size=config.num_repetitions_intra)\n",
    "\n",
    "# Define the base directory\n",
    "cwd = os.getcwd()\n",
    "if config.data_split_method in ['intra','inter']:\n",
    "    data_base_dir = os.path.join(cwd,'data_auto_split')\n",
    "else:\n",
    "    data_base_dir = os.path.join(cwd,'data_manual_split')\n",
    "        \n",
    "exp_base_dir = os.path.join(data_base_dir,config.experiment_name)\n",
    "\n",
    "# Define a list of experiments\n",
    "if os.path.exists(exp_base_dir):\n",
    "    experiment_name_list = [exp_base_dir]\n",
    "else:\n",
    "    print('No such experiment. These are all existing experiments: ')\n",
    "    experiment_name_list = create_dir_list_no_hidden_dir(data_base_dir)\n",
    "    for curr_exp_name in experiment_name_list:\n",
    "        print(curr_exp_name)\n",
    "    print('Input [c] if you want to run these experiments')\n",
    "    pdb.set_trace()\n",
    "\n",
    "num_exps = len(experiment_name_list)\n",
    "num_ML_methods = len(ML_method_list)\n",
    "\n",
    "# Count the number of classification methods. Intentionally didn't implement the set approach \n",
    "# to make sure of the consistency between the orders of the lists.\n",
    "ML_classif_method_list = []\n",
    "for curr_ML_method in ML_method_list:\n",
    "    if curr_ML_method in supported_classif_methods:\n",
    "        ML_classif_method_list.append(curr_ML_method)\n",
    "num_classif_methods = len(ML_classif_method_list)\n",
    "\n",
    "# Generate color list for classification bar plots\n",
    "color_list_for_bar_plots = []\n",
    "for idx_ML_method in range(num_classif_methods):\n",
    "    color_list_for_bar_plots.append(rgb_to_hex((random.randint(0,255), random.randint(0,255), random.randint(0,255))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment(s)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************************************\n",
      "Begin experiment  1 / 1 : EX15-4-prime-stocked-exo3v15\n",
      "***********************************************************\n",
      "Classes =  ['HEK', 'HepG', 'MCF7', 'MDAMB', 'PC3']\n",
      "and their corresponding colors:  ['#008000', '#ff00ff', '#b8860b', '#008080', '#ff0000']\n",
      "------ Begin: Get common wavenumbers ------\n",
      "1/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HEK/HEK-No1-P1.txt\n",
      "2/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HEK/HEK-No1-P2.txt\n",
      "3/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HEK/HEK-No1-P3.txt\n",
      "4/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HEK/HEK-No2-P1.txt\n",
      "5/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HEK/HEK-No2-P2.txt\n",
      "6/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HEK/HEK-No2-P3.txt\n",
      "7/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HEK/HEK-No3-P1.txt\n",
      "8/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HEK/HEK-No3-P2.txt\n",
      "9/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HEK/HEK-No3-P3.txt\n",
      "10/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HEK/HEK-No4-P1.txt\n",
      "11/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HEK/HEK-No4-P2.txt\n",
      "12/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HEK/HEK-No4-P3.txt\n",
      "13/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HEK/HEK-No5-P1.txt\n",
      "14/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HEK/HEK-No5-P2.txt\n",
      "15/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HEK/HEK-No5-P3.txt\n",
      "16/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HepG/HepG-No1-P1.txt\n",
      "17/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HepG/HepG-No1-P2.txt\n",
      "18/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HepG/HepG-No1-P3.txt\n",
      "19/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HepG/HepG-No2-P1.txt\n",
      "20/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HepG/HepG-No2-P2.txt\n",
      "21/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HepG/HepG-No2-P3.txt\n",
      "22/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HepG/HepG-No3-P1.txt\n",
      "23/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HepG/HepG-No3-P2.txt\n",
      "24/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HepG/HepG-No3-P3.txt\n",
      "25/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HepG/HepG-No4-P1.txt\n",
      "26/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HepG/HepG-No4-P2.txt\n",
      "27/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HepG/HepG-No4-P3.txt\n",
      "28/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HepG/HepG-No5-P1.txt\n",
      "29/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HepG/HepG-No5-P2.txt\n",
      "30/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HepG/HepG-No5-P3.txt\n",
      "31/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MCF7/MCF7-No1-P1.txt\n",
      "32/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MCF7/MCF7-No1-P2.txt\n",
      "33/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MCF7/MCF7-No1-P3.txt\n",
      "34/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MCF7/MCF7-No2-P1.txt\n",
      "35/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MCF7/MCF7-No2-P2.txt\n",
      "36/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MCF7/MCF7-No2-P3.txt\n",
      "37/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MCF7/MCF7-No3-P1.txt\n",
      "38/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MCF7/MCF7-No3-P2.txt\n",
      "39/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MCF7/MCF7-No3-P3.txt\n",
      "40/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MCF7/MCF7-No4-P1.txt\n",
      "41/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MCF7/MCF7-No4-P2.txt\n",
      "42/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MCF7/MCF7-No4-P3.txt\n",
      "43/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MCF7/MCF7-No5-P1.txt\n",
      "44/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MCF7/MCF7-No5-P2.txt\n",
      "45/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MCF7/MCF7-No5-P3.txt\n",
      "46/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MDAMB/MDAMB-No1-P1.txt\n",
      "47/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MDAMB/MDAMB-No1-P2.txt\n",
      "48/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MDAMB/MDAMB-No1-P3.txt\n",
      "49/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MDAMB/MDAMB-No2-P1.txt\n",
      "50/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MDAMB/MDAMB-No2-P2.txt\n",
      "51/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MDAMB/MDAMB-No2-P3.txt\n",
      "52/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MDAMB/MDAMB-No3-P1.txt\n",
      "53/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MDAMB/MDAMB-No3-P2.txt\n",
      "54/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MDAMB/MDAMB-No3-P3.txt\n",
      "55/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MDAMB/MDAMB-No4-P1.txt\n",
      "56/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MDAMB/MDAMB-No4-P2.txt\n",
      "57/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MDAMB/MDAMB-No4-P3.txt\n",
      "58/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MDAMB/MDAMB-No5-P1.txt\n",
      "59/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MDAMB/MDAMB-No5-P2.txt\n",
      "60/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/MDAMB/MDAMB-No5-P3.txt\n",
      "61/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/PC3/PC3-No1-P1.txt\n",
      "62/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/PC3/PC3-No1-P2.txt\n",
      "63/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/PC3/PC3-No1-P3.txt\n",
      "64/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/PC3/PC3-No2-P1.txt\n",
      "65/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/PC3/PC3-No2-P2.txt\n",
      "66/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/PC3/PC3-No2-P3.txt\n",
      "67/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/PC3/PC3-No3-P1.txt\n",
      "68/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/PC3/PC3-No3-P2.txt\n",
      "69/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/PC3/PC3-No3-P3.txt\n",
      "70/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/PC3/PC3-No4-P1.txt\n",
      "71/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/PC3/PC3-No4-P2.txt\n",
      "72/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/PC3/PC3-No4-P3.txt\n",
      "73/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/PC3/PC3-No5-P1.txt\n",
      "74/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/PC3/PC3-No5-P2.txt\n",
      "75/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/PC3/PC3-No5-P3.txt\n",
      "------ End: Get common wavenumbers ------\n",
      "------ Begin: Extract all the spectra ------\n",
      "The preloaded wavenumbers are not the same as the desired ones. Overwrite the preloaded data.\n",
      "Done processing 1/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HEK/HEK-No1-P1.txt\n",
      "\n",
      "The preloaded wavenumbers are not the same as the desired ones. Overwrite the preloaded data.\n",
      "Done processing 2/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HEK/HEK-No1-P2.txt\n",
      "\n",
      "The preloaded wavenumbers are not the same as the desired ones. Overwrite the preloaded data.\n",
      "Done processing 3/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HEK/HEK-No1-P3.txt\n",
      "\n",
      "The preloaded wavenumbers are not the same as the desired ones. Overwrite the preloaded data.\n",
      "Done processing 4/75: /home/jupyter-ichatnun/projects/SERS_Analysis/data_manual_split/EX15-4-prime-stocked-exo3v15/train/HEK/HEK-No2-P1.txt\n",
      "\n",
      "The preloaded wavenumbers are not the same as the desired ones. Overwrite the preloaded data.\n"
     ]
    }
   ],
   "source": [
    "for idx_exp, curr_exp_path in enumerate(experiment_name_list):\n",
    "    \n",
    "    # Prepare a directory for saving the results\n",
    "    curr_exp_name = os.path.basename(curr_exp_path)\n",
    "    results_path = os.path.join(cwd,config.results_folder_name, curr_exp_name, config.data_split_method)\n",
    "\n",
    "    if config.REMOVE_BASELINE:\n",
    "        results_path += '_baseline_removed'\n",
    "\n",
    "    if os.path.exists(results_path):\n",
    "        shutil.rmtree(results_path)\n",
    "    \n",
    "    os.makedirs(results_path)\n",
    "    \n",
    "    # Copy the config file\n",
    "    shutil.copy2('./config/current_config.py', os.path.join(results_path))\n",
    "    \n",
    "        \n",
    "    print('***********************************************************')\n",
    "    print('Begin experiment ', idx_exp+1, '/', num_exps,':',curr_exp_name)\n",
    "    print('***********************************************************')\n",
    "    \n",
    "    # Extract classes\n",
    "    if config.data_split_method in ['intra','inter']:\n",
    "        class_list = get_class_names(curr_exp_path)\n",
    "        \n",
    "    elif config.data_split_method in ['by-folders']:\n",
    "        class_list_train = get_class_names(os.path.join(curr_exp_path,'train'))\n",
    "        class_list_test = get_class_names(os.path.join(curr_exp_path,'test'))\n",
    "        \n",
    "        if set(class_list_train) == set(class_list_test):\n",
    "            class_list = class_list_test\n",
    "        else:\n",
    "            print('Training and test class lists are not the same.')\n",
    "            sys.exit(1)\n",
    "        \n",
    "    print('Classes = ', class_list)\n",
    "            \n",
    "    # Generate a color list for each class\n",
    "    colors_list,color_dict = createColorList(config.color_dict,class_list)\n",
    "    print('and their corresponding colors: ', colors_list)\n",
    "    \n",
    "    ########## Load data ##########\n",
    "    \n",
    "    # If the user has provided the raman shift file, load it.\n",
    "    ramanshifts_filepath = os.path.join(curr_exp_path,'raman_shifts.csv')\n",
    "    if os.path.exists(ramanshifts_filepath):\n",
    "        shutil.copy2(ramanshifts_filepath, os.path.join(results_path))\n",
    "        df = pd.read_csv(ramanshifts_filepath)\n",
    "        desired_ramanshifts = df['shifts'].values\n",
    "        del df\n",
    "        print('Use the raman shifts specified in', ramanshifts_filepath)\n",
    "    else:\n",
    "        # Determine common wavenumbers\n",
    "        if config.data_split_method in ['intra','inter']:\n",
    "            desired_ramanshifts = getCommonWavenumbers(curr_exp_path, class_list)\n",
    "            \n",
    "        elif config.data_split_method in ['by-folders']:\n",
    "            # Determine common wavenumbers based on the training data\n",
    "            desired_ramanshifts = getCommonWavenumbers(os.path.join(curr_exp_path,'train'), class_list)\n",
    "            \n",
    "        df_out = pd.DataFrame(desired_ramanshifts,columns=['shifts'])\n",
    "        df_out.to_csv(os.path.join(results_path,'raman_shifts.csv'),index=False,index_label='shifts')\n",
    "        del df_out\n",
    "\n",
    "\n",
    "    # Load the data from the 'intra' and 'inter' cases\n",
    "    if config.data_split_method in ['intra','inter']:\n",
    "        \n",
    "        # Extract the spectra and interpolate the wavenumbers to align with 'common_wavenumbers'\n",
    "        spectra, _ = extractAllSpectra(curr_exp_path, \n",
    "                                       class_list,\n",
    "                                       desired_wavenumbers=desired_ramanshifts,\n",
    "                                       REMOVE_BASELINE=config.REMOVE_BASELINE,\n",
    "                                       OVERWRITE_PRELOADED_DATA=config.OVERWRITE_PRELOADED_DATA)\n",
    "        del desired_ramanshifts\n",
    "\n",
    "        ########## Define the data-splitting parameters ##########\n",
    "        if config.data_split_method in ['intra']:\n",
    "            num_repetitions = config.num_repetitions_intra\n",
    "            fraction_test =  config.fraction_test_intra\n",
    "\n",
    "        elif config.data_split_method in ['inter']:\n",
    "\n",
    "            # Figure out the minimum number of files in a class for the current experiment\n",
    "            min_num_files_per_class = 100000\n",
    "            for curr_class in class_list:\n",
    "                curr_num_files_per_class = len(glob.glob(os.path.join(curr_exp_path,curr_class,'*.txt')))\n",
    "                if min_num_files_per_class > curr_num_files_per_class:\n",
    "                    min_num_files_per_class = curr_num_files_per_class\n",
    "\n",
    "            num_repetitions = min_num_files_per_class\n",
    "            fraction_test = 1.0/min_num_files_per_class\n",
    "            \n",
    "    elif config.data_split_method in ['by-folders']:\n",
    "        num_repetitions = 1\n",
    "        spectra_training, _ = extractAllSpectra(os.path.join(curr_exp_path,'train'), \n",
    "                                                class_list,\n",
    "                                                desired_wavenumbers=desired_ramanshifts,\n",
    "                                                REMOVE_BASELINE=config.REMOVE_BASELINE,\n",
    "                                                OVERWRITE_PRELOADED_DATA=config.OVERWRITE_PRELOADED_DATA)\n",
    "        spectra_test, _ = extractAllSpectra(os.path.join(curr_exp_path,'test'), \n",
    "                                            class_list,\n",
    "                                            desired_wavenumbers=desired_ramanshifts,\n",
    "                                            REMOVE_BASELINE=config.REMOVE_BASELINE,\n",
    "                                            OVERWRITE_PRELOADED_DATA=config.OVERWRITE_PRELOADED_DATA)\n",
    "        \n",
    "    \n",
    "    acc_all_reps_all_methods = np.zeros((num_repetitions,num_classif_methods))\n",
    "    \n",
    "    for idx_rep in range(num_repetitions):\n",
    "        \n",
    "        print('Rep ', idx_rep+1, '/', num_repetitions,'\\n')            \n",
    "\n",
    "        ########## Perform training/test data splitting ##########\n",
    "        if config.data_split_method in ['intra','inter']:\n",
    "            params_data_splitting = {'data_split_method':config.data_split_method,\n",
    "                                     'spectra':spectra,\n",
    "                                     'class_list':class_list,\n",
    "                                     'fraction_test':fraction_test}\n",
    "\n",
    "            if config.data_split_method in ['intra']:\n",
    "                params_data_splitting.update({'random_seed': random_seed_list[idx_rep]})\n",
    "                spectra_training, spectra_test, labels_training, labels_test = trainTestSplitting(**params_data_splitting)\n",
    "\n",
    "            elif config.data_split_method in ['inter']:\n",
    "                params_data_splitting.update({'idx_target_file_for_inter_test': idx_rep})\n",
    "                spectra_training, spectra_test, labels_training, labels_test = trainTestSplitting(**params_data_splitting)\n",
    "        \n",
    "        elif config.data_split_method in ['by-folders']:\n",
    "            spectra_training, labels_training = loadSpectraAndLabels(spectra_training, class_list)\n",
    "            spectra_test, labels_test = loadSpectraAndLabels(spectra_test, class_list)\n",
    "            \n",
    "    \n",
    "        print('# of training spectra = ', spectra_training.shape[0])\n",
    "        print('# of test spectra = ', spectra_test.shape[0])\n",
    "\n",
    "        ########## Apply each ML method ##########\n",
    "        count_classif_method = 0\n",
    "        params = {'class_list':class_list,\n",
    "                 'x_train':spectra_training,\n",
    "                 'y_train':labels_training,\n",
    "                 'x_test':spectra_test,\n",
    "                 'y_test':labels_test,\n",
    "                 'color_dict':color_dict}\n",
    "        \n",
    "        for idx_ML_method, curr_ML_method in enumerate(ML_method_list):\n",
    "            \n",
    "            print('\\n\\tML method ', idx_ML_method+1, '/',num_ML_methods,':',curr_ML_method)\n",
    "            \n",
    "            # Prepare the folder to save the results\n",
    "            temp_base_results_path = os.path.join(results_path,\n",
    "                       'rep'+str(idx_rep+1),\n",
    "                       curr_ML_method)\n",
    "            \n",
    "            if not os.path.exists(temp_base_results_path):\n",
    "                os.makedirs(temp_base_results_path)\n",
    "                \n",
    "            params.update({'results_path':temp_base_results_path})\n",
    "                    \n",
    "            \n",
    "            # Apply the current ML model\n",
    "            if curr_ML_method in supported_classif_methods:\n",
    "                \n",
    "                acc = performAnalysis(method_name=curr_ML_method, params=params)\n",
    "                \n",
    "                # Update the classification accuracy matrix\n",
    "                acc_all_reps_all_methods[idx_rep,count_classif_method] = acc\n",
    "                count_classif_method += 1\n",
    "                \n",
    "            else: \n",
    "                performAnalysis(method_name=curr_ML_method, params=params)\n",
    "            \n",
    "    # Save the overall accuracies\n",
    "    mean_acc = np.mean(acc_all_reps_all_methods,axis=0)\n",
    "    std_acc = np.std(acc_all_reps_all_methods,axis=0)\n",
    "    stats = np.concatenate((acc_all_reps_all_methods,np.expand_dims(mean_acc,axis=0)),axis=0)\n",
    "    stats = np.concatenate((stats,np.expand_dims(std_acc,axis=0)),axis=0)\n",
    "\n",
    "    df = pd.DataFrame(stats, columns = ML_classif_method_list)\n",
    "\n",
    "    df_index_temp = []\n",
    "    for idx_rep in range(num_repetitions):\n",
    "        df_index_temp.append('Rep '+ str(idx_rep+1))\n",
    "    df_index_temp.append('Mean')\n",
    "    df_index_temp.append('Std')\n",
    "    df.index = df_index_temp\n",
    "\n",
    "    df.to_csv(os.path.join(results_path,'accuracy_test_reps.csv'))\n",
    "\n",
    "    # Create and save the classification accuracy bar plot\n",
    "    plt.figure()\n",
    "    plt.bar(ML_classif_method_list, mean_acc, yerr=std_acc, color=color_list_for_bar_plots)\n",
    "    plt.xlabel('ML methods')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid()\n",
    "    plt.savefig(fname=os.path.join(results_path, 'acc_test_bar_plot.jpg'),dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "print('Done')\n",
    "print('***********************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exosomes",
   "language": "python",
   "name": "exosomes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
