{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install webcolors\n",
    "!{sys.executable} -m pip install plotly==5.7.0\n",
    "!{sys.executable} -m pip install --upgrade nbformat\n",
    "!{sys.executable} -m pip install tune-sklearn ray[tune]\n",
    "!{sys.executable} -m pip install packaging\n",
    "!{sys.executable} -m pip install -U kaleido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Import necessary packages\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import pdb, itertools, os, time, sys, re, random, pickle, shutil\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from utils import *\n",
    "from config import current_config as config\n",
    "from models.performAnalysis import performAnalysis\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Sans\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Check the validity of the paremeters\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ML methods that will be used include ['pca', 'pc-lda', 'lda-rf', 'lda-svm']\n"
     ]
    }
   ],
   "source": [
    "supported_classif_methods = ['pc-lda', 'rf', 'pc-rf', 'lda-rf', 'svm','pc-svm','lda-svm']\n",
    "supported_ML_methods = supported_classif_methods + ['pca']\n",
    "\n",
    "\n",
    "ML_method_list = config.ML_method_list\n",
    "# Get rid of unsupported ML methods\n",
    "for curr_ML_method in ML_method_list:\n",
    "    if not (curr_ML_method in supported_ML_methods):\n",
    "        ML_method_list.remove(curr_ML_method)\n",
    "        print(curr_ML_method,'is currently unsupported')\n",
    "print('The ML methods that will be used include', ML_method_list)\n",
    "\n",
    "if not (config.data_split_method in ['intra','inter','by-folders']):\n",
    "    print('Invalid data_split_method.')\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Prepare some information\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such experiment. These are all existing experiments: \n",
      "/home/jupyter-ichatnun/projects/SERS_Analysis/data_auto_split/EX1-raw\n",
      "Input [c] if you want to run these experiments\n",
      "--Return--\n",
      "> <ipython-input-4-96d0b79f7a56>(23)<module>()->None\n",
      "-> pdb.set_trace()\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  c\n"
     ]
    }
   ],
   "source": [
    "# Generate a list of random seeds to perform experiments\n",
    "if config.data_split_method == 'intra':\n",
    "    random_seed_list = np.random.randint(config.num_repetitions_intra*10, size=config.num_repetitions_intra)\n",
    "\n",
    "# Define the base directory\n",
    "cwd = os.getcwd()\n",
    "if config.data_split_method in ['intra','inter']:\n",
    "    data_base_dir = os.path.join(cwd,'data_auto_split')\n",
    "else:\n",
    "    data_base_dir = os.path.join(cwd,'data_manual_split')\n",
    "        \n",
    "exp_base_dir = os.path.join(data_base_dir,config.experiment_name)\n",
    "\n",
    "# Define a list of experiments\n",
    "if os.path.exists(exp_base_dir):\n",
    "    experiment_name_list = [exp_base_dir]\n",
    "else:\n",
    "    print('No such experiment. These are all existing experiments: ')\n",
    "    experiment_name_list = create_dir_list_no_hidden_dir(data_base_dir)\n",
    "    for curr_exp_name in experiment_name_list:\n",
    "        print(curr_exp_name)\n",
    "    print('Input [c] if you want to run these experiments')\n",
    "    pdb.set_trace()\n",
    "\n",
    "num_exps = len(experiment_name_list)\n",
    "num_ML_methods = len(ML_method_list)\n",
    "\n",
    "# Count the number of classification methods. Intentionally didn't implement the set approach \n",
    "# to make sure of the consistency between the orders of the lists.\n",
    "ML_classif_method_list = []\n",
    "for curr_ML_method in ML_method_list:\n",
    "    if curr_ML_method in supported_classif_methods:\n",
    "        ML_classif_method_list.append(curr_ML_method)\n",
    "num_classif_methods = len(ML_classif_method_list)\n",
    "\n",
    "# Generate color list for classification bar plots\n",
    "color_list_for_bar_plots = []\n",
    "for idx_ML_method in range(num_classif_methods):\n",
    "    color_list_for_bar_plots.append(rgb_to_hex((random.randint(0,255), random.randint(0,255), random.randint(0,255))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment(s)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************************************\n",
      "Begin experiment  1 / 1 : EX1-raw\n",
      "***********************************************************\n",
      "Classes =  ['Buffer', 'HEK']\n",
      "and their corresponding colors:  ['#0000ff', '#008000']\n",
      "Use the raman shifts specified in /home/jupyter-ichatnun/projects/SERS_Analysis/data_auto_split/EX1-raw/raman_shifts.csv\n",
      "------ Begin: Extract all the spectra ------\n",
      "/home/jupyter-ichatnun/projects/SERS_Analysis/data_auto_split/EX1-raw/Buffer/Buffer_onSERS_Pos1_spectra.pkl already exists, so just load it.\n",
      "Done processing 1/6: /home/jupyter-ichatnun/projects/SERS_Analysis/data_auto_split/EX1-raw/Buffer/Buffer_onSERS_Pos1.txt\n",
      "\n",
      "/home/jupyter-ichatnun/projects/SERS_Analysis/data_auto_split/EX1-raw/Buffer/Buffer_onSERS_Pos2_spectra.pkl already exists, so just load it.\n",
      "Done processing 2/6: /home/jupyter-ichatnun/projects/SERS_Analysis/data_auto_split/EX1-raw/Buffer/Buffer_onSERS_Pos2.txt\n",
      "\n",
      "/home/jupyter-ichatnun/projects/SERS_Analysis/data_auto_split/EX1-raw/Buffer/Buffer_onSERS_Pos3_spectra.pkl already exists, so just load it.\n",
      "Done processing 3/6: /home/jupyter-ichatnun/projects/SERS_Analysis/data_auto_split/EX1-raw/Buffer/Buffer_onSERS_Pos3.txt\n",
      "\n",
      "/home/jupyter-ichatnun/projects/SERS_Analysis/data_auto_split/EX1-raw/HEK/HEK-0_inBuffer_Pos1_spectra.pkl already exists, so just load it.\n",
      "Done processing 4/6: /home/jupyter-ichatnun/projects/SERS_Analysis/data_auto_split/EX1-raw/HEK/HEK-0_inBuffer_Pos1.txt\n",
      "\n",
      "/home/jupyter-ichatnun/projects/SERS_Analysis/data_auto_split/EX1-raw/HEK/HEK-0_inBuffer_Pos2_spectra.pkl already exists, so just load it.\n",
      "Done processing 5/6: /home/jupyter-ichatnun/projects/SERS_Analysis/data_auto_split/EX1-raw/HEK/HEK-0_inBuffer_Pos2.txt\n",
      "\n",
      "/home/jupyter-ichatnun/projects/SERS_Analysis/data_auto_split/EX1-raw/HEK/HEK-0_inBuffer_Pos3_spectra.pkl already exists, so just load it.\n",
      "Done processing 6/6: /home/jupyter-ichatnun/projects/SERS_Analysis/data_auto_split/EX1-raw/HEK/HEK-0_inBuffer_Pos3.txt\n",
      "\n",
      "------ End: Extract all the spectra ------\n",
      "Rep  1 / 1 \n",
      "\n",
      "# of training spectra =  2500\n",
      "# of test spectra =  1250\n",
      "\n",
      "\tML method  1 / 4 : pca\n",
      "\n",
      "\tML method  2 / 4 : pc-lda\n",
      "Confusion matrix, without normalization\n",
      "[[623   2]\n",
      " [  2 623]]\n",
      "\n",
      "\tML method  3 / 4 : lda-rf\n",
      "Confusion matrix, without normalization\n",
      "[[623   2]\n",
      " [  2 623]]\n",
      "\n",
      "\tML method  4 / 4 : lda-svm\n",
      "Confusion matrix, without normalization\n",
      "[[623   2]\n",
      " [  2 623]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "***********************************************************\n"
     ]
    }
   ],
   "source": [
    "for idx_exp, curr_exp_path in enumerate(experiment_name_list):\n",
    "    \n",
    "    # Prepare a directory for saving the results\n",
    "    curr_exp_name = os.path.basename(curr_exp_path)\n",
    "    results_path = os.path.join(cwd,config.results_folder_name, curr_exp_name, config.data_split_method)\n",
    "\n",
    "    if config.REMOVE_BASELINE:\n",
    "        results_path += '_baseline_removed'\n",
    "\n",
    "    if os.path.exists(results_path):\n",
    "        shutil.rmtree(results_path)\n",
    "    \n",
    "    os.makedirs(results_path)\n",
    "    \n",
    "    # Copy the config file\n",
    "    shutil.copy2('./config/current_config.py', os.path.join(results_path))\n",
    "    \n",
    "        \n",
    "    print('***********************************************************')\n",
    "    print('Begin experiment ', idx_exp+1, '/', num_exps,':',curr_exp_name)\n",
    "    print('***********************************************************')\n",
    "    \n",
    "    # Extract classes\n",
    "    if config.data_split_method in ['intra','inter']:\n",
    "        class_list = get_class_names(curr_exp_path)\n",
    "        \n",
    "    elif config.data_split_method in ['by-folders']:\n",
    "        class_list_train = get_class_names(os.path.join(curr_exp_path,'train'))\n",
    "        class_list_test = get_class_names(os.path.join(curr_exp_path,'test'))\n",
    "        \n",
    "        if set(class_list_train) == set(class_list_test):\n",
    "            class_list = class_list_test\n",
    "        else:\n",
    "            print('Training and test class lists are not the same.')\n",
    "            sys.exit(1)\n",
    "        \n",
    "    print('Classes = ', class_list)\n",
    "            \n",
    "    # Generate a color list for each class\n",
    "    colors_list,color_dict = createColorList(config.color_dict,class_list)\n",
    "    print('and their corresponding colors: ', colors_list)\n",
    "    \n",
    "    ########## Load data ##########\n",
    "    \n",
    "    # If the user has provided the raman shift file, load it.\n",
    "    ramanshifts_filepath = os.path.join(curr_exp_path,'raman_shifts.csv')\n",
    "    if os.path.exists(ramanshifts_filepath):\n",
    "        df = pd.read_csv(ramanshifts_filepath)\n",
    "        desired_ramanshifts = df['shifts'].values\n",
    "        del df\n",
    "        print('Use the raman shifts specified in', ramanshifts_filepath)\n",
    "        shutil.copy2(ramanshifts_filepath, os.path.join(results_path))\n",
    "\n",
    "    else:\n",
    "        # Determine common wavenumbers\n",
    "        desired_ramanshifts = getCommonWavenumbers(curr_exp_path, class_list)\n",
    "            \n",
    "        df_out = pd.DataFrame(desired_ramanshifts,columns=['shifts'])\n",
    "        df_out.to_csv(os.path.join(results_path,'raman_shifts.csv'),index=False,index_label='shifts')\n",
    "        del df_out\n",
    "\n",
    "\n",
    "    # Load the data from the 'intra' and 'inter' cases\n",
    "    if config.data_split_method in ['intra','inter']:\n",
    "        \n",
    "        # Extract the spectra and interpolate the wavenumbers to align with 'common_wavenumbers'\n",
    "        spectra, _ = extractAllSpectra(curr_exp_path, \n",
    "                                       class_list,\n",
    "                                       desired_wavenumbers=desired_ramanshifts,\n",
    "                                       REMOVE_BASELINE=config.REMOVE_BASELINE,\n",
    "                                       OVERWRITE_PRELOADED_DATA=config.OVERWRITE_PRELOADED_DATA)\n",
    "        del desired_ramanshifts\n",
    "\n",
    "        ########## Define the data-splitting parameters ##########\n",
    "        if config.data_split_method in ['intra']:\n",
    "            num_repetitions = config.num_repetitions_intra\n",
    "            fraction_test =  config.fraction_test_intra\n",
    "\n",
    "        elif config.data_split_method in ['inter']:\n",
    "\n",
    "            # Figure out the minimum number of files in a class for the current experiment\n",
    "            min_num_files_per_class = 100000\n",
    "            for curr_class in class_list:\n",
    "                curr_num_files_per_class = len(glob.glob(os.path.join(curr_exp_path,curr_class,'*.txt')))\n",
    "                if min_num_files_per_class > curr_num_files_per_class:\n",
    "                    min_num_files_per_class = curr_num_files_per_class\n",
    "\n",
    "            num_repetitions = min_num_files_per_class\n",
    "            fraction_test = 1.0/min_num_files_per_class\n",
    "            \n",
    "    elif config.data_split_method in ['by-folders']:\n",
    "        num_repetitions = 1\n",
    "        spectra_training, _ = extractAllSpectra(os.path.join(curr_exp_path,'train'), \n",
    "                                                class_list,\n",
    "                                                desired_wavenumbers=desired_ramanshifts,\n",
    "                                                REMOVE_BASELINE=config.REMOVE_BASELINE,\n",
    "                                                OVERWRITE_PRELOADED_DATA=config.OVERWRITE_PRELOADED_DATA)\n",
    "        spectra_test, _ = extractAllSpectra(os.path.join(curr_exp_path,'test'), \n",
    "                                            class_list,\n",
    "                                            desired_wavenumbers=desired_ramanshifts,\n",
    "                                            REMOVE_BASELINE=config.REMOVE_BASELINE,\n",
    "                                            OVERWRITE_PRELOADED_DATA=config.OVERWRITE_PRELOADED_DATA)\n",
    "        \n",
    "    \n",
    "    acc_all_reps_all_methods = np.zeros((num_repetitions,num_classif_methods))\n",
    "    \n",
    "    for idx_rep in range(num_repetitions):\n",
    "        \n",
    "        print('Rep ', idx_rep+1, '/', num_repetitions,'\\n')            \n",
    "\n",
    "        ########## Perform training/test data splitting ##########\n",
    "        if config.data_split_method in ['intra','inter']:\n",
    "            params_data_splitting = {'data_split_method':config.data_split_method,\n",
    "                                     'spectra':spectra,\n",
    "                                     'class_list':class_list,\n",
    "                                     'fraction_test':fraction_test}\n",
    "\n",
    "            if config.data_split_method in ['intra']:\n",
    "                params_data_splitting.update({'random_seed': random_seed_list[idx_rep]})\n",
    "                spectra_training, spectra_test, labels_training, labels_test = trainTestSplitting(**params_data_splitting)\n",
    "\n",
    "            elif config.data_split_method in ['inter']:\n",
    "                params_data_splitting.update({'idx_target_file_for_inter_test': idx_rep})\n",
    "                spectra_training, spectra_test, labels_training, labels_test = trainTestSplitting(**params_data_splitting)\n",
    "        \n",
    "        elif config.data_split_method in ['by-folders']:\n",
    "            spectra_training, labels_training = loadSpectraAndLabels(spectra_training, class_list)\n",
    "            spectra_test, labels_test = loadSpectraAndLabels(spectra_test, class_list)\n",
    "            \n",
    "    \n",
    "        print('# of training spectra = ', spectra_training.shape[0])\n",
    "        print('# of test spectra = ', spectra_test.shape[0])\n",
    "\n",
    "        ########## Apply each ML method ##########\n",
    "        count_classif_method = 0\n",
    "        params = {'class_list':class_list,\n",
    "                 'x_train':spectra_training,\n",
    "                 'y_train':labels_training,\n",
    "                 'x_test':spectra_test,\n",
    "                 'y_test':labels_test,\n",
    "                 'color_dict':color_dict}\n",
    "        \n",
    "        for idx_ML_method, curr_ML_method in enumerate(ML_method_list):\n",
    "            \n",
    "            print('\\n\\tML method ', idx_ML_method+1, '/',num_ML_methods,':',curr_ML_method)\n",
    "            \n",
    "            # Prepare the folder to save the results\n",
    "            temp_base_results_path = os.path.join(results_path,\n",
    "                       'rep'+str(idx_rep+1),\n",
    "                       curr_ML_method)\n",
    "            \n",
    "            if not os.path.exists(temp_base_results_path):\n",
    "                os.makedirs(temp_base_results_path)\n",
    "                \n",
    "            params.update({'results_path':temp_base_results_path})\n",
    "                    \n",
    "            \n",
    "            # Apply the current ML model\n",
    "            if curr_ML_method in supported_classif_methods:\n",
    "                \n",
    "                acc = performAnalysis(method_name=curr_ML_method, params=params)\n",
    "                \n",
    "                # Update the classification accuracy matrix\n",
    "                acc_all_reps_all_methods[idx_rep,count_classif_method] = acc\n",
    "                count_classif_method += 1\n",
    "                \n",
    "            else: \n",
    "                performAnalysis(method_name=curr_ML_method, params=params)\n",
    "            \n",
    "    # Save the overall accuracies\n",
    "    mean_acc = np.mean(acc_all_reps_all_methods,axis=0)\n",
    "    std_acc = np.std(acc_all_reps_all_methods,axis=0)\n",
    "    stats = np.concatenate((acc_all_reps_all_methods,np.expand_dims(mean_acc,axis=0)),axis=0)\n",
    "    stats = np.concatenate((stats,np.expand_dims(std_acc,axis=0)),axis=0)\n",
    "\n",
    "    df = pd.DataFrame(stats, columns = ML_classif_method_list)\n",
    "\n",
    "    df_index_temp = []\n",
    "    for idx_rep in range(num_repetitions):\n",
    "        df_index_temp.append('Rep '+ str(idx_rep+1))\n",
    "    df_index_temp.append('Mean')\n",
    "    df_index_temp.append('Std')\n",
    "    df.index = df_index_temp\n",
    "\n",
    "    df.to_csv(os.path.join(results_path,'accuracy_test_reps.csv'))\n",
    "\n",
    "    # Create and save the classification accuracy bar plot\n",
    "    plt.figure()\n",
    "    plt.bar(ML_classif_method_list, mean_acc, yerr=std_acc, color=color_list_for_bar_plots)\n",
    "    plt.xlabel('ML methods')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid()\n",
    "    plt.savefig(fname=os.path.join(results_path, 'acc_test_bar_plot.jpg'),dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "print('Done')\n",
    "print('***********************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exosomes",
   "language": "python",
   "name": "exosomes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
